{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec73668-7259-4d58-9b7b-40e7ec9a62e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import time\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "from IPython.display import display\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5a3418-9c28-49ef-80c6-8c12ee7ddb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/Data/federated_learning/large_vlm_distillation_ood/Resnet18_classification/s_cars_ood/\"\n",
    "\n",
    "train_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomRotation(15),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "test_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(root=dataset_dir+\"train\", transform = train_tfms)\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle=True, num_workers = 2)\n",
    "\n",
    "dataset2 = torchvision.datasets.ImageFolder(root=dataset_dir+\"test\", transform = test_tfms)\n",
    "testloader = torch.utils.data.DataLoader(dataset2, batch_size = 32, shuffle=False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "937cfeb9-3a76-4bf0-b4a5-2293e67ea1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, n_epochs = 25):\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    test_accuracies = []\n",
    "    # set the model to train mode initially\n",
    "    model.train()\n",
    "    model=model.to('cuda')\n",
    "    for epoch in range(n_epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # get the inputs and assign them to cuda\n",
    "            inputs, labels = data\n",
    "            \n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "             # forward + backward + optimize\n",
    "                \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # calculate the loss/acc later\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels==predicted).sum().item()\n",
    "\n",
    "        epoch_duration = time.time()-since\n",
    "        epoch_loss = running_loss/len(trainloader)\n",
    "        epoch_acc = 100/32*running_correct/len(trainloader)\n",
    "        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
    "        \n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "        model.eval()\n",
    "        test_acc = eval_model(model)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        # re-set the model to train mode after validating\n",
    "        model.train()\n",
    "        scheduler.step(test_acc)\n",
    "        since = time.time()\n",
    "    print('Finished Training')\n",
    "    return model, losses, accuracies, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "828f67c7-faef-4df1-877d-e5f0ea1d5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            images, labels = data\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_ft(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        test_acc = 100.0 * correct / total\n",
    "    print(f'Accuracy of the network on the test images: {test_acc:.2f}%')\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132e319a-d337-472c-ad75-d75b4c9e389f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ariel/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ariel/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 196)\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.01,momentum=0.9)\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ef399-503c-4cd4-a365-b88b4180d851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, duration: 75 s, loss: 3.1784, acc: 31.0551\n",
      "Accuracy of the network on the test images: 0.24%\n",
      "Epoch 2, duration: 72 s, loss: 1.0014, acc: 74.7791\n",
      "Accuracy of the network on the test images: 0.00%\n",
      "Epoch 3, duration: 74 s, loss: 0.5436, acc: 85.8173\n",
      "Accuracy of the network on the test images: 0.12%\n"
     ]
    }
   ],
   "source": [
    "model_ft, training_losses, training_accs, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333948c-c32a-419a-a758-df4185156790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, axarr = plt.subplots(2,2, figsize = (12, 8))\n",
    "# axarr[0, 0].plot(training_losses)\n",
    "# axarr[0, 0].set_title(\"Training loss\")\n",
    "# axarr[0, 1].plot(training_accs)\n",
    "# axarr[0, 1].set_title(\"Training acc\")\n",
    "# axarr[1, 0].plot(test_accs)\n",
    "\n",
    "# axarr[1, 0].set_title(\"Test acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943230d8-f4e6-47a1-be13-96e6c27f5c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc1154-bbff-46da-a222-bbfee189d355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f80272b9-2f90-4d31-be84-bebaa4554fac",
   "metadata": {},
   "source": [
    "## My own resnet18 train on ood stanford car dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "956fca44-5907-47bd-8777-86512b96ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a64d240-0580-4a74-8842-c88c59a61a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset_dir = \"/Data/federated_learning/large_vlm_distillation_ood/Resnet18_classification/car_data/car_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be6112-ee1a-49b0-b3cf-342d21d0f27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ae4981a-16da-4b40-87b1-d8982b699d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomRotation(15),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "test_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ed773-25b3-4c6e-9b6f-0546ac06b91d",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca0704b6-26b6-4aa4-97ec-d884280ffff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=196, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(root=dataset_dir+\"train\", transform = train_tfms)\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size = 16, shuffle=True, num_workers = 2)\n",
    "\n",
    "dataset2 = torchvision.datasets.ImageFolder(root=dataset_dir+\"test\", transform = test_tfms)\n",
    "testloader = torch.utils.data.DataLoader(dataset2, batch_size = 16, shuffle=False, num_workers = 2)\n",
    "\n",
    "# Load the pre-trained ResNet18 model\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer\n",
    "num_classes = 196\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, num_classes)\n",
    "resnet18.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad95a3-9c6d-41e6-8e24-80bda0a871f6",
   "metadata": {},
   "source": [
    "## Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43e55b50-81a4-4052-861e-a8e07ea34de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "\n",
    "def train_model(train_loader, val_loader, model, criterion, num_epochs, lr, optimizer_class):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = optimizer_class(model.parameters(), lr=lr, momentum=0.9, weight_decay=0.0005, nesterov=True)\n",
    "    max_train_acc = 0.0\n",
    "    max_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_accs = []\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to the correct device\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_losses.append(loss.item())\n",
    "            acc = accuracy(outputs, labels)\n",
    "            train_accs.append(acc.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = np.mean(train_losses)\n",
    "        train_acc = np.mean(train_accs)\n",
    "        max_train_acc = max(max_train_acc, train_acc)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_accs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)  # Move data to the correct device\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_losses.append(loss.item())\n",
    "                acc = accuracy(outputs, labels)\n",
    "                val_accs.append(acc.item())\n",
    "\n",
    "        val_loss = np.mean(val_losses)\n",
    "        val_acc = np.mean(val_accs)\n",
    "        max_val_acc = max(max_val_acc, val_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {100*(train_acc):.2f}, % \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {100*(val_acc):.2f}, %\")\n",
    "\n",
    "    return max_train_acc, max_val_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7510e73-1d3b-4510-8506-70a91b3d57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, num_epochs, lr, optimizer = nn.CrossEntropyLoss(),25, 0.001, optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "181d57d5-bce5-48c1-a963-47d8e1c105aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 5.1324, Train Acc: 2.93, % Val Loss: 4.6384, Val Acc: 8.95, %\n",
      "Epoch [2/25], Train Loss: 4.3107, Train Acc: 12.55, % Val Loss: 3.8060, Val Acc: 21.70, %\n",
      "Epoch [3/25], Train Loss: 3.5761, Train Acc: 26.93, % Val Loss: 3.1030, Val Acc: 34.97, %\n",
      "Epoch [4/25], Train Loss: 2.8977, Train Acc: 43.32, % Val Loss: 2.4779, Val Acc: 49.10, %\n",
      "Epoch [5/25], Train Loss: 2.3357, Train Acc: 57.15, % Val Loss: 1.9775, Val Acc: 60.10, %\n",
      "Epoch [6/25], Train Loss: 1.8678, Train Acc: 66.63, % Val Loss: 1.5944, Val Acc: 69.40, %\n",
      "Epoch [7/25], Train Loss: 1.4869, Train Acc: 75.01, % Val Loss: 1.3322, Val Acc: 73.46, %\n",
      "Epoch [8/25], Train Loss: 1.2110, Train Acc: 80.75, % Val Loss: 1.1256, Val Acc: 77.24, %\n",
      "Epoch [9/25], Train Loss: 0.9936, Train Acc: 84.32, % Val Loss: 0.9708, Val Acc: 78.96, %\n",
      "Epoch [10/25], Train Loss: 0.8280, Train Acc: 87.02, % Val Loss: 0.8629, Val Acc: 81.57, %\n",
      "Epoch [11/25], Train Loss: 0.6832, Train Acc: 89.86, % Val Loss: 0.7720, Val Acc: 83.49, %\n",
      "Epoch [12/25], Train Loss: 0.5763, Train Acc: 91.81, % Val Loss: 0.6946, Val Acc: 84.34, %\n",
      "Epoch [13/25], Train Loss: 0.4940, Train Acc: 92.92, % Val Loss: 0.6706, Val Acc: 84.93, %\n",
      "Epoch [14/25], Train Loss: 0.4276, Train Acc: 94.62, % Val Loss: 0.6103, Val Acc: 85.92, %\n",
      "Epoch [15/25], Train Loss: 0.3700, Train Acc: 95.15, % Val Loss: 0.5804, Val Acc: 85.79, %\n",
      "Epoch [16/25], Train Loss: 0.3216, Train Acc: 96.14, % Val Loss: 0.5584, Val Acc: 86.72, %\n",
      "Epoch [17/25], Train Loss: 0.2814, Train Acc: 96.80, % Val Loss: 0.5434, Val Acc: 87.30, %\n",
      "Epoch [18/25], Train Loss: 0.2488, Train Acc: 97.40, % Val Loss: 0.5185, Val Acc: 86.92, %\n",
      "Epoch [19/25], Train Loss: 0.2241, Train Acc: 97.69, % Val Loss: 0.4987, Val Acc: 87.80, %\n",
      "Epoch [20/25], Train Loss: 0.2065, Train Acc: 97.83, % Val Loss: 0.4921, Val Acc: 87.92, %\n",
      "Epoch [21/25], Train Loss: 0.1860, Train Acc: 98.22, % Val Loss: 0.4861, Val Acc: 87.98, %\n",
      "Epoch [22/25], Train Loss: 0.1669, Train Acc: 98.55, % Val Loss: 0.4693, Val Acc: 88.11, %\n",
      "Epoch [23/25], Train Loss: 0.1531, Train Acc: 98.64, % Val Loss: 0.4508, Val Acc: 88.61, %\n",
      "Epoch [24/25], Train Loss: 0.1401, Train Acc: 98.77, % Val Loss: 0.4501, Val Acc: 88.46, %\n",
      "Epoch [25/25], Train Loss: 0.1283, Train Acc: 98.99, % Val Loss: 0.4604, Val Acc: 88.16, %\n"
     ]
    }
   ],
   "source": [
    "max_train_acc, max_val_acc = train_model(trainloader, testloader, resnet18.to(device), criterion, num_epochs, lr, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcfcf75-4d36-40cc-aedf-e6d82e8c050e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
